{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5468be7-7b35-49c7-a24b-c66e0bc97fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6635d25c-bcc5-43be-aa8f-2a74c7b82542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "from fastbm25 import fastbm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a259fc38-229b-4551-986d-32f540d619d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fea3294a-50d2-4b74-9375-5b051a107a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/QA_modelBM25_k_4\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "def evaluate_type_BM25(T, k):\n",
    "    if T:\n",
    "        K = k\n",
    "        MODEL_PATH = 'model/QA_modelBM25_k_'+str(K)\n",
    "    else:\n",
    "        K = k\n",
    "        MODEL_PATH = 'model/QA_model_TFIDF_k_'+str(K)\n",
    "    print(MODEL_PATH)\n",
    "    device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(device)\n",
    "    return MODEL_PATH, K, device\n",
    "\n",
    "MODEL_PATH, K, device = evaluate_type_BM25(True, 4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b6da2-bac0-4eff-8ce9-b221cfceedc6",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "774bdead-0f1a-4def-bf6a-972b61e141d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/train.txt'\n",
    "DEV_PATH = 'data/val.txt'\n",
    "TEST_PATH = 'data/test.txt'\n",
    "TEST_ANSWER_PATH = 'data/Assignment2_test_answer.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddd77046-b89c-45e4-b46a-86ef202bb991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_txt(path):\n",
    "    QandA = []\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in tqdm(file):\n",
    "            #print(line)\n",
    "            if line != \"\\n\":\n",
    "                splitted = line.split(\"|||\")\n",
    "                sentences = splitted[0]\n",
    "                question  = r\" \".join(splitted[1].split())\n",
    "                answer    = re.sub(\"\\n\",\"\",splitted[2])\n",
    "                answer = r\" \".join(answer.split())\n",
    "                QandA.append((sentences, question, answer))\n",
    "    return QandA\n",
    "\n",
    "def read_answer_data(path):\n",
    "    QandA = []\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in tqdm(file):\n",
    "            #print(line)\n",
    "            if line != \"\\n\":\n",
    "                splitted = line.split(\"|||\")\n",
    "                question = r\" \".join(splitted[0].split())\n",
    "                answer  = re.sub(\"\\n\",\"\",splitted[-1])\n",
    "                answer = r\" \".join(answer.split())\n",
    "                QandA.append((question, answer))\n",
    "    return QandA\n",
    "\n",
    "def correct_test_answer(data, answer):\n",
    "    QandA = []\n",
    "    for origin, correct in zip(data, answer):\n",
    "        sentence = origin[0]\n",
    "        question = origin[1]\n",
    "        answer   = correct[1]\n",
    "        QandA.append((sentence, question, answer))\n",
    "    return  QandA   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a560c18e-58af-471f-9e7a-75bd1f2bec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99820it [00:01, 64737.45it/s]\n",
      "13893it [00:00, 67530.58it/s]\n",
      "27248it [00:00, 73603.52it/s]\n",
      "27248it [00:00, 231682.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data  = read_data_from_txt(TRAIN_PATH)\n",
    "del train_data[51641] #51641報錯\n",
    "valid_data  = read_data_from_txt(DEV_PATH)\n",
    "# test_data\n",
    "test_data   = read_data_from_txt(TEST_PATH)\n",
    "test_answer = read_answer_data(TEST_ANSWER_PATH)\n",
    "test_data   = correct_test_answer(test_data, test_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346dec2b-0063-44f5-ac91-042237167740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99819\n",
      "13893\n",
      "27248\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(valid_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df129de1-f087-4400-8e9a-12e694110090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average:  17.27763505578391\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Result=[]\n",
    "total = 0\n",
    "for i in range(len(test_data)):\n",
    "    muti_answer_count = 0\n",
    "    sentences = re.findall(r'<s>(.*?)</s>', test_data[i][0])\n",
    "    for sen in sentences:\n",
    "        if test_data[i][2] in sen:\n",
    "            muti_answer_count = muti_answer_count+1\n",
    "    Result.append(muti_answer_count)\n",
    "    total = total+muti_answer_count\n",
    "print('average: ', total/len(Result))\n",
    "# 文本中，含有答案超過XX次以上的list    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(Result, bins=10, label= [0,5,10,15,20,25,30,35,40,45,50,60,70], cumulative =True)\n",
    "plt.show()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeaf0a55-f17a-435d-a345-41443cdcc7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 99819/99819 [00:16<00:00, 6214.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every answer is in context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 13893/13893 [00:02<00:00, 6200.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every answer is in context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_answer(data):\n",
    "    index = []\n",
    "    for sentences, question, answer in tqdm(data):\n",
    "        ans = \"FALSE\"\n",
    "        sentences = re.findall(r'<s>(.*?)</s>', sentences)\n",
    "        for sentence in sentences:\n",
    "            try:\n",
    "                if answer in sentence:\n",
    "                    ans = \"TRUE\" \n",
    "            except:\n",
    "                continue\n",
    "        if ans == \"FALSE\":\n",
    "                index.append(i)\n",
    "    if len(index) == 0:\n",
    "        print(\"Every answer is in context.\")\n",
    "check_answer(train_data)\n",
    "check_answer(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31c8eb4-5cb1-4ab4-90fe-b322e536505c",
   "metadata": {},
   "source": [
    "# 用tf-idf 選取和問題最相近的句子，包含答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d428cfe-086d-41f7-85c3-3347058aa96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_top_k_articles(query, docs, k=1):\\n\\n    # Initialize a vectorizer that removes English stop words\\n    vectorizer = TfidfVectorizer(analyzer=\"word\", stop_words=\\'english\\')\\n\\n    # Create a corpus of query and documents and convert to TFIDF vectors\\n    query_and_docs = [query] + docs\\n    matrix = vectorizer.fit_transform(query_and_docs)\\n\\n    # Holds our cosine similarity scores\\n    scores = []\\n\\n    # The first vector is our query text, so compute the similarity of our query against all document vectors\\n    for i in range(1, len(query_and_docs)):\\n        scores.append(cosine_similarity(matrix[0], matrix[i])[0][0])\\n\\n    # Sort list of scores and return the top k highest scoring documents\\n    sorted_list = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\\n    top_doc_indices = [x[0] for x in sorted_list[:k]]\\n    top_docs = [docs[x] for x in top_doc_indices]\\n  \\n    return top_docs\\n\\ndef get_topk_tfidf_sentence(data):\\n    contexts = []\\n    for sentences, question, answer in tqdm(data):\\n        contained_answer_sentence = []\\n        sentences = re.findall(r\\'<s>(.*?)</s>\\', sentences)\\n        for sentence in sentences:\\n            if answer in sentence:\\n                contained_answer_sentence.append(sentence)\\n        doc = get_top_k_articles(question, contained_answer_sentence)\\n        context = \". \".join(doc)\\n        contexts.append(context)\\n    return contexts\\ntrain_contexts = get_topk_tfidf_sentence(train_data)\\nvalid_contexts =   get_topk_tfidf_sentence(valid_data)\\ntest_contexts  = get_topk_tfidf_sentence(test_data)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def get_top_k_articles(query, docs, k=1):\n",
    "\n",
    "    # Initialize a vectorizer that removes English stop words\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"word\", stop_words='english')\n",
    "\n",
    "    # Create a corpus of query and documents and convert to TFIDF vectors\n",
    "    query_and_docs = [query] + docs\n",
    "    matrix = vectorizer.fit_transform(query_and_docs)\n",
    "\n",
    "    # Holds our cosine similarity scores\n",
    "    scores = []\n",
    "\n",
    "    # The first vector is our query text, so compute the similarity of our query against all document vectors\n",
    "    for i in range(1, len(query_and_docs)):\n",
    "        scores.append(cosine_similarity(matrix[0], matrix[i])[0][0])\n",
    "\n",
    "    # Sort list of scores and return the top k highest scoring documents\n",
    "    sorted_list = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "    top_doc_indices = [x[0] for x in sorted_list[:k]]\n",
    "    top_docs = [docs[x] for x in top_doc_indices]\n",
    "  \n",
    "    return top_docs\n",
    "\n",
    "def get_topk_tfidf_sentence(data):\n",
    "    contexts = []\n",
    "    for sentences, question, answer in tqdm(data):\n",
    "        contained_answer_sentence = []\n",
    "        sentences = re.findall(r'<s>(.*?)</s>', sentences)\n",
    "        for sentence in sentences:\n",
    "            if answer in sentence:\n",
    "                contained_answer_sentence.append(sentence)\n",
    "        doc = get_top_k_articles(question, contained_answer_sentence)\n",
    "        context = \". \".join(doc)\n",
    "        contexts.append(context)\n",
    "    return contexts\n",
    "train_contexts = get_topk_tfidf_sentence(train_data)\n",
    "valid_contexts =   get_topk_tfidf_sentence(valid_data)\n",
    "test_contexts  = get_topk_tfidf_sentence(test_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54cf77cd-d710-4650-b7a4-a78f56b2511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 99819/99819 [01:57<00:00, 852.18it/s]\n",
      "100%|████████████████████████████████████| 13893/13893 [00:16<00:00, 868.30it/s]\n",
      "100%|████████████████████████████████████| 27248/27248 [00:31<00:00, 862.47it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_topk_bm25_sentence(data, k):\n",
    "    contexts = []\n",
    "    for sentences, question, answer in tqdm(data):\n",
    "        contained_answer_sentence = []\n",
    "        sentences = re.findall(r'<s>(.*?)</s>', sentences)\n",
    "        for sentence in sentences:\n",
    "            if answer in sentence:\n",
    "                contained_answer_sentence.append(sentence)\n",
    "        tokenized_corpus = [doc.lower().split(\" \") for doc in contained_answer_sentence]\n",
    "        FASTBM25 = fastbm25(tokenized_corpus)\n",
    "        tokenized_answer = question.lower().split(\" \")\n",
    "        doc = FASTBM25.top_k_sentence(tokenized_answer, k=k)\n",
    "        final_doc = []\n",
    "        for list_doc, _,score in doc:\n",
    "            final_doc.append(\" \".join(list_doc))\n",
    "        context = \". \".join(final_doc)\n",
    "        contexts.append(context)\n",
    "    return contexts\n",
    "\n",
    "train_contexts = get_topk_bm25_sentence(train_data, K)\n",
    "valid_contexts = get_topk_bm25_sentence(valid_data, K)\n",
    "test_contexts  = get_topk_bm25_sentence(test_data,  K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc45e935-3121-4efc-9239-2a6d8ddeae7b",
   "metadata": {},
   "source": [
    "# 轉換成Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b22824-930b-4364-b439-1d6949bf00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(data, contexts):\n",
    "    ques = []\n",
    "    ans= []\n",
    "    for sentences, question, answer in data:\n",
    "        ques.append(question)\n",
    "        ans.append(answer)\n",
    "    return pd.DataFrame({'sentences':contexts,'question':ques,'answer':ans})\n",
    "train_data = convert_to_dataframe(train_data, train_contexts)\n",
    "valid_data = convert_to_dataframe(valid_data, valid_contexts)\n",
    "test_data =  convert_to_dataframe(test_data, test_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0536454f-cb60-4bfe-b32c-78bbb9c9b7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76613</th>\n",
       "      <td>bagna cauda al' la vecchia recipe food52 jan 17 , 2011 bagna cauda means warm bath idea serve sharp bitter flavored vegetables dip bath salt taste dipping hot bath leaves radicchio treviso , red white endive , slices fennel , n't burn either avoid little tins oil packed anchovies morocco .  italian hot bath , bagna cauda selection crisp , fresh meaning hot bath italian , bagna cauda array fresh vegetables recipe bagna cauda piedmontese hot dip garlic , anchovies , olive oil , fresh salad vegetables dressing drizzle fish chicken takes 2 days make , layers flavor held within golden .  food drink rome frommer 's agnolotti crescent shape pasta shell stuffed mix chopped meat , spices , bagna cauda hot well seasoned sauce , heavily flavored anchovies , designed dipping raw vegetables literally translated hot bath fritto misto deep fried medley whatever small fish , shellfish , squid .  food timeline history notes charlotte millet full charlotte mixture , putting means pastry tube bag , top halves candied cherries , whole nut egg batter fritters containing meat , fish fruit fried lard oil lay dozen ratafia cakes dipped noyeau bagna cauda hot bath olive oil , anchovies garlic</td>\n",
       "      <td>bagna cauda , hot bath , vegetables dipped oil mixture flavored tiny fish</td>\n",
       "      <td>anchovies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_random_elements(dataset, num_examples=1):\n",
    "    df = dataset.sample(n = num_examples)\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "show_random_elements(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4868ee98-14ba-4a60-a812-1888c457d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99741\n",
      "13885\n",
      "27217\n"
     ]
    }
   ],
   "source": [
    "def clean_answer_not_in_context(data):\n",
    "    index_ids=[]\n",
    "    for i in range(len(data)):\n",
    "        if data['answer'].iloc[i] in data['sentences'].iloc[i]:\n",
    "            continue\n",
    "        else:\n",
    "            index_ids.append(i)\n",
    "    data = data.drop(index_ids, axis=0)\n",
    "    print(len(data))\n",
    "    return data\n",
    "\n",
    "train_data = clean_answer_not_in_context(train_data)\n",
    "valid_data = clean_answer_not_in_context(valid_data)\n",
    "test_data  = clean_answer_not_in_context(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d1445d-7837-4526-a51e-a1b46f8d37a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5702f7-78e5-4352-8b60-e6237e434409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999321da-7300-4195-b283-62521c2550eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokennize_list(data):\n",
    "    data_question = data['question'].tolist()\n",
    "    data_context = data['sentences'].tolist()\n",
    "    return data_question, data_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8df9f390-6399-4f0b-8df8-276a12fe6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_question, train_context = get_tokennize_list(train_data)\n",
    "valid_question, valid_context = get_tokennize_list(valid_data)\n",
    "test_question,  test_context  = get_tokennize_list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad7dd308-7f92-46e7-a019-5a22fa1c1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_question, train_context, truncation=True, padding=True)\n",
    "val_encodings   = tokenizer(valid_question, valid_context, truncation=True, padding=True)\n",
    "test_encodings  = tokenizer(test_question, test_context, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00bd02bf-c0f6-406c-a71c-715ecc6d05ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] last 8 years life, galileo house arrest espousing man's theory [SEP] lebowski sweater replica jun 17, 2013 history last 8 years life, galileo house arrest espousing man's theory copernicus espn's top 10 time. images knickerless women jun 17, 2013 history last 8 years life, galileo house arrest espousing man's theory copernicus espn's top 10 time. christa mcauliffe autopsy jun 17, 2013 history last 8 years life, galileo house arrest espousing man's theory copernicus espn's top 10 time. mary nightingale botox jun 17, 2013 history last 8 years life, galileo house arrest espousing man's theory copernicus espn's top 10 time [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_encodings['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8ab73-cda1-4f54-876a-8a03be778328",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 找答案的start end index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf0d315-ac97-4b61-905a-1401f3d6a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Start_End_index(data):\n",
    "    data['start'] = [y.index(x) for x,y in zip(data[\"answer\"],data[\"sentences\"])]\n",
    "    data['end']   = [x+len(str(y)) for x,y in zip(data[\"start\"],data[\"answer\"])]\n",
    "get_Start_End_index(train_data)\n",
    "get_Start_End_index(valid_data)\n",
    "get_Start_End_index(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eeadd48-fc3e-48ff-94fa-feee17840650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lebowski sweater replica jun 17 , 2013 histor...</td>\n",
       "      <td>last 8 years life , galileo house arrest espou...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>113</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jim thorpe bio , stats , results olympics spo...</td>\n",
       "      <td>2 1912 olympian football star carlisle indian ...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yuma arizona oddities part 3 jul 21 , 2011 yu...</td>\n",
       "      <td>city yuma state record average 4 , 055 hours s...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gravestone famous ancestor roger sherman sign...</td>\n",
       "      <td>signer dec indep , framer constitution mass , ...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>176</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>full text catalog educational films internet ...</td>\n",
       "      <td>title aesop fable , insect shared billing gras...</td>\n",
       "      <td>ant</td>\n",
       "      <td>251</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0   lebowski sweater replica jun 17 , 2013 histor...   \n",
       "1   jim thorpe bio , stats , results olympics spo...   \n",
       "2   yuma arizona oddities part 3 jul 21 , 2011 yu...   \n",
       "3   gravestone famous ancestor roger sherman sign...   \n",
       "4   full text catalog educational films internet ...   \n",
       "\n",
       "                                            question      answer  start  end  \n",
       "0  last 8 years life , galileo house arrest espou...  copernicus    113  123  \n",
       "1  2 1912 olympian football star carlisle indian ...  jim thorpe      1   11  \n",
       "2  city yuma state record average 4 , 055 hours s...     arizona      6   13  \n",
       "3  signer dec indep , framer constitution mass , ...  john adams    176  186  \n",
       "4  title aesop fable , insect shared billing gras...         ant    251  254  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "724fd848-c32e-444b-9f0b-c52dece503f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'copernicus'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentences'].iloc[0][113:123]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497799e4-ac87-4d75-b9ef-58e34bafc684",
   "metadata": {
    "tags": []
   },
   "source": [
    "# add token positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1c9cf6e-3f34-4cac-a7fb-4c12eb74ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answer = train_data[['start', 'end']].to_dict('records')\n",
    "valid_answer = valid_data[['start', 'end']].to_dict('records')\n",
    "test_answer  = test_data[['start', 'end']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cd79af5-0bf7-4b8a-8da7-f2070c2d3835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copernicus\n",
      "47\n",
      "49\n",
      "copernicus\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(train_data['answer'].iloc[i])\n",
    "a = train_encodings.char_to_token(i, train_answer[i]['start'], 1)\n",
    "print(a)\n",
    "b = train_encodings.char_to_token(i, train_answer[i]['end']-1, 1)\n",
    "print(b)\n",
    "print(tokenizer.decode(train_encodings['input_ids'][i][47:b+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24954ba0-9a6f-420c-8968-875574a11d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['start'],1))\n",
    "        end_positions.append(encodings.char_to_token(i, answers[i]['end']-1,1))\n",
    "\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "            \n",
    "        shift = 1\n",
    "        while end_positions[-1] is None:\n",
    "            if answers[i]['end'] - shift>=0:\n",
    "                end_positions[-1] = encodings.char_to_token(i, answers[i]['end'] - shift, 1)\n",
    "                shift += 1 \n",
    "            else:\n",
    "                break\n",
    "            \n",
    "    encodings.update({'start': start_positions, 'end': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, train_answer)\n",
    "add_token_positions(val_encodings, valid_answer)\n",
    "add_token_positions(test_encodings, test_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bf1d76e-2865-4a5f-9602-ec4e2b2f50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert char_based_id to token_based_id\n",
    "# Find the corossponding token id after input being tokenized\n",
    "add_token_positions(train_encodings, train_answer)\n",
    "add_token_positions(val_encodings, valid_answer)\n",
    "add_token_positions(test_encodings, test_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76f41d22-155f-4ccf-8748-6c5082b6aff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start', 'end'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4db46f0a-2c1f-4a6c-a116-079bcde29c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "49\n",
      "36\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings['start'][0])\n",
    "print(train_encodings['end'][0])\n",
    "print(val_encodings['start'][0])\n",
    "print(val_encodings['end'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c945d874-6b91-4713-862d-97c0d7efb559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oratory\n",
      "oratory\n"
     ]
    }
   ],
   "source": [
    "i=23\n",
    "print(train_data['sentences'].iloc[i][train_answer[i]['start']:train_answer[i]['end']])\n",
    "print(tokenizer.decode(train_encodings['input_ids'][i][train_encodings['start'][i]:train_encodings['end'][i]+1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381f5a8-6242-47ed-a3cb-b05c5e3407aa",
   "metadata": {},
   "source": [
    "# convert to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76557abc-b0a1-4f14-9062-1adeb15ba9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            return {key: torch.tensor(value[idx]) for key, value in self.encodings.items()}\n",
    "        except:\n",
    "            print(idx)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1f3a9ae-0f63-418c-b390-ee1197c57d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QADataset(train_encodings)\n",
    "val_dataset   = QADataset(val_encodings)\n",
    "test_dataset  = QADataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5d2e738-5daa-4a8f-af49-1ded38a49528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101, 22620,  1394,  3003,   117,  1724,  4249,  2247,   117,  1642,\n",
       "          6048, 12200, 22217,  1116,   102,  1714,  6746, 18464,  5752,  2025,\n",
       "          8419,  2158, 22620,  1394,  3003,   117,  1724,  4249,  2247,   117,\n",
       "          1642,  6048, 12200, 22217,  1116,   117, 23123,  1158,  2787,  6394,\n",
       "           119,  1185,  2707, 10615,  1489,   117,  1369,  1270,  7761,  1821,\n",
       "         26237,  1389,  5752, 22620,  1394,  3003,   117,  1724,  4249,  2247,\n",
       "           117,  1642,  6048, 12200, 22217,  1116, 23123,  1158,  2787,  6394,\n",
       "           119,  1299,  1186,  1299,  1186,  6048,  3377, 22620,  1394,  1821,\n",
       "         26237,  1161, 23123,  1158,  2787,  5016, 23123,  1158,  2787,   117,\n",
       "           175, 18318, 25300,  1202,  5031, 14846,  8037,  7959,  5075,   117,\n",
       "          3494,  2766,  2286,  3003,  1346,  2761,   117,  4249,  2247,  1338,\n",
       "         12890, 19587,  1676, 12477,  1616,   117,  1724,  1893,  1603,  1642,\n",
       "           117,  1141,  9616, 12200, 22217,  1116, 20856,  2227,  9521,  1226,\n",
       "          1299,  6738, 15625,   119, 14940,  3761,  4249,  2247, 14044,  3965,\n",
       "          1204, 23123,  1158,  2787,  4156,  1297,  2435,  3003,  3593,  2208,\n",
       "          1632,  8492,  2944, 12200, 22217,  1116,  1344,  1278,   117, 23123,\n",
       "          1158,  2787,  4927,  1684,  8598,  6409,  1162,   117,  1278,  3054,\n",
       "           117,  1724,  1148,  1558,  2281,   117,  3336,  1145,  9440,   117,\n",
       "          1642,  1821, 26237,  1389,  4035, 23655,  2737,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'start': tensor(36),\n",
       " 'end': tensor(38)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674f8be-152b-4b8c-9377-fc6491c55358",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d7b0ddb-6819-4ae5-9446-d18b50cea7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class QAModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(QAModel, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.fc = torch.nn.Linear(768, 2)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=True)\n",
    "        logits = output[0]\n",
    "        out = self.fc(logits)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0acf7597-0e1d-4e17-b6b1-a7640efaa198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "# Put model on device\n",
    "model = QAModel().to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084bcc6b-77e5-46a7-a96a-01f320c4dea1",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d7b5768-3a39-4a3e-a260-880fd894ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack data into dataloader by batch\n",
    "batch_size   = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1515b417-4606-44a5-a2b7-606e9f4a380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12468\n",
      "1736\n",
      "3403\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(valid_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6bd4552-cd8f-4b3d-a25d-5a4345199aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = 3\n",
    "loss_fct = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcefb50d-c7fb-4c88-af70-b298500bae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(valid_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(valid_loader, leave=True)\n",
    "        for batch_id, batch in enumerate(loop):\n",
    "            input_ids      = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start          = batch['start'].to(device)\n",
    "            end            = batch['end'].to(device)\n",
    "\n",
    "            # model output\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "            start_logits, end_logits = torch.split(outputs, 1, 2)\n",
    "\n",
    "            start_logits = start_logits.squeeze(-1).contiguous()\n",
    "            end_logits   = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "            start_loss = loss_fct(start_logits, start)\n",
    "            end_loss   = loss_fct(end_logits, end)\n",
    "\n",
    "            loss = start_loss + end_loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        print('Validation Loss {:.4f}'.format(running_loss / len(valid_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c3418-4101-4e76-84c7-8c8fae8f5b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████| 12468/12468 [2:12:14<00:00,  1.57it/s, loss=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss 1.8243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1736/1736 [05:18<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss 1.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████| 12468/12468 [2:12:12<00:00,  1.57it/s, loss=12.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss 3.9557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1736/1736 [05:13<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss 12.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   2%|▎                | 258/12468 [02:44<2:07:40,  1.59it/s, loss=12.5]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 2:  41%|██████▌         | 5079/12468 [53:37<1:17:18,  1.59it/s, loss=12.5]"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch_id, batch in enumerate(loop):\n",
    "        # reset\n",
    "        optim.zero_grad()\n",
    "\n",
    "        input_ids      = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start          = batch['start'].to(device)\n",
    "        end            = batch['end'].to(device)\n",
    "\n",
    "        # model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        start_logits, end_logits = torch.split(outputs, 1, 2)\n",
    "\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits   = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        start_loss = loss_fct(start_logits, start)\n",
    "        end_loss = loss_fct(end_logits, end)\n",
    "        loss = start_loss + end_loss\n",
    "        # calculate loss\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    print('Training Loss {:.4f}'.format(running_loss / len(train_loader)))\n",
    "    evaluate(valid_loader)\n",
    "    \n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b098185-a58b-4829-88cd-e50f3e00b72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd3275-7a0f-4de9-bf5c-bc01ccd55a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TheModelClass(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb31815-0108-4a1c-9883-7b21950ad954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    predict_pos = []\n",
    "    sub_output = []\n",
    "\n",
    "    loop = tqdm(test_loader, leave=True)\n",
    "    for batch_id, batch in enumerate(loop):\n",
    "        input_ids      = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "\n",
    "        # model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        \n",
    "        start_logits, end_logits = torch.split(outputs, 1, 2)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits   = end_logits.squeeze(-1).contiguous()\n",
    "\n",
    "        start_prdict = torch.argmax(start_logits, 1).cpu().numpy()\n",
    "        end_prdict   = torch.argmax(end_logits, 1).cpu().numpy()\n",
    "\n",
    "        for i in range(len(input_ids)):\n",
    "            predict_pos.append((start_prdict[i].item(), end_prdict[i].item()))\n",
    "            sub = tokenizer.decode(input_ids[i][start_prdict[i]:end_prdict[i]+1])\n",
    "            sub_output.append(sub)\n",
    "    \n",
    "    return sub_output, predict_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30265c-ebe2-444f-ab51-aa5fc5f73501",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_output, predict_pos = predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644686c-c4e9-4f66-865e-0f4838acdc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1604be-f788-4d92-8d6c-ada4a4329d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_token_string(sentence):\n",
    "    # print(sentence)\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    for i in range(len(tokens)):\n",
    "        if len(tokens[i]) == 1:\n",
    "            tokens[i] = re.sub(r\"[!\\\"#$%&\\'()*\\+, -.\\/:;<=>?@\\[\\\\\\]^_`{|}~]\", '', tokens[i])\n",
    "    while '' in tokens:\n",
    "        tokens.remove('')\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18b197-10be-4b7c-afa4-bd2cbb331966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_post_fn(test, sub_output):\n",
    "    sub = []\n",
    "    for i in range(len(test)):\n",
    "\n",
    "        sub_pred = sub_output[i].split()\n",
    "\n",
    "        temp = sub_pred.copy()\n",
    "        if sub_pred is None:\n",
    "            sub_pred = []\n",
    "        else:\n",
    "            for j in range(len(temp)):\n",
    "                if temp[j] == '[SEP]':\n",
    "                    sub_pred.remove('[SEP]')\n",
    "                if temp[j] == '[PAD]':\n",
    "                    sub_pred.remove('[PAD]')\n",
    "\n",
    "        sub.append(' '.join(sub_pred))\n",
    "        \n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff3961-2b47-4af0-a55f-5df0c03e6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = get_output_post_fn(test_data, sub_output)\n",
    "test_data['predict'] = sub\n",
    "test_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84219a4e-a5ce-475c-a05f-35b1b426d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(X, Y):\n",
    "    X_, Y_ = [], []\n",
    "    \n",
    "    X_ = nltk_token_string(X)\n",
    "    Y_ = nltk_token_string(Y)\n",
    "\n",
    "    m = len(X_)\n",
    "    n = len(Y_)\n",
    " \n",
    "    # declaring the array for storing the dp values\n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    " \n",
    "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0 :\n",
    "                L[i][j] = 0\n",
    "            elif X_[i-1] == Y_[j-1]:\n",
    "                L[i][j] = L[i-1][j-1]+1\n",
    "            else:\n",
    "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    " \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
    "    return L[m][n]\n",
    "\n",
    "\n",
    "def acc(full, sub):\n",
    "    common = lcs(full, sub)\n",
    "    union = len(full) + len(sub) - common\n",
    "    accuracy = float(common/union)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942d36b-6c35-4832-b72e-e2273f7f4b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "acc_sum = 0\n",
    "for i in range(valid_data.shape[0]):\n",
    "    accuracy = acc(valid_data.iloc[i][\"answer\"], valid_data.iloc[i]['predict'])\n",
    "    acc_sum += accuracy\n",
    "\n",
    "print(\"lcs accuracy: \", acc_sum/valid_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd8cb9-0b0e-4555-bbc8-30b473aaf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "import string\n",
    "  \n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "  \n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "  \n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "  \n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "  \n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "  \n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "    \n",
    "def get_tokens(s):\n",
    "    if not s:\n",
    "        return []\n",
    "    return normalize_answer(s).split()\n",
    "   \n",
    "def compute_exact(a_gold, a_pred):\n",
    "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    "  \n",
    "def compute_f1(a_gold, a_pred):\n",
    "    gold_toks = get_tokens(a_gold)\n",
    "    pred_toks = get_tokens(a_pred)\n",
    "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "    num_same = sum(common.values())\n",
    "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "        return int(gold_toks == pred_toks)\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(pred_toks)\n",
    "    recall = 1.0 * num_same / len(gold_toks)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def f1_metric(data):\n",
    "    f1_score = 0.0\n",
    "    for answer, pred in zip(data[\"answer\"], data['predict']):\n",
    "        f1_score+=compute_f1(answer, pred)\n",
    "    print(\"f1 score: {}\".format(f1_score/len(data)))\n",
    "f1_metric(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06da9bd-b401-4992-b554-eadbe7e71f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub_output, test_predict_pos = predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848347fc-3825-46b7-9efa-d3f7857b4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = get_output_post_fn(test_data, test_sub_output)\n",
    "test_data['predict'] = test_sub\n",
    "test_data.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f752b-15f5-4a2f-b02f-4f76af36b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7794167-420f-49f9-9ada-66fd9b503387",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit_data  = read_data_from_txt(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27ffbd-ee5a-47e9-a094-91f64fd40830",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95096e1-f4f6-404e-89c5-25ac1a79f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "question = []\n",
    "for i,j,k in test_submit_data:\n",
    "    text.append(i)\n",
    "    question.append(j)\n",
    "print(len(text))\n",
    "print(len(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad9b39-dd3d-4817-acc3-192eca61e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "path = 'data/final-submit.txt'\n",
    "f = open(path, 'w')\n",
    "for question, answer in zip(question, test_sub):\n",
    "    f.write(question+\"|||\"+answer+\"\\n\")\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec43a6-9306-4162-9507-34b8eb303de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13319070-d339-4f4e-8cf4-579a2d89384a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05a78ea-027c-4227-9680-5b6ba9ae20c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d0160-21a3-484b-bbea-3fb4279b2c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
